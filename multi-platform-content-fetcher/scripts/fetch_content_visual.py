#!/usr/bin/env python3
"""
å¤šå¹³å°å†…å®¹è·å–å™¨ - å¯è§†åŒ–å¢å¼ºç‰ˆ
å¸¦å®æ—¶è¿›åº¦æ˜¾ç¤ºçš„å¤šå¹³å°å†…å®¹è·å–å·¥å…·
"""

import json
import hashlib
import argparse
import time
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional
import sys

# æ·»åŠ  visual-progress æ¡†æ¶è·¯å¾„
visual_progress_path = Path(__file__).parent.parent.parent / "visual-progress"
if visual_progress_path.exists():
    sys.path.insert(0, str(visual_progress_path))
    from core.visual_progress import VisualProgress
    VISUAL_PROGRESS_AVAILABLE = True
else:
    VISUAL_PROGRESS_AVAILABLE = False
    print("âš ï¸  visual-progress æ¡†æ¶æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨åŸºç¡€è¿›åº¦æ˜¾ç¤º")


class ContentFetcherVisual:
    """å†…å®¹è·å–å™¨ä¸»ç±» - å¯è§†åŒ–å¢å¼ºç‰ˆ"""

    def __init__(self, db_path: str = None, enable_visual: bool = True):
        """åˆå§‹åŒ–å†…å®¹è·å–å™¨

        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
            enable_visual: æ˜¯å¦å¯ç”¨å¯è§†åŒ–è¿›åº¦
        """
        if db_path is None:
            skill_dir = Path(__file__).parent.parent
            db_path = skill_dir / "content_db.json"

        self.db_path = Path(db_path)
        self.db = self._load_database()
        self.enable_visual = enable_visual and VISUAL_PROGRESS_AVAILABLE

        # å¹³å°å›¾æ ‡æ˜ å°„
        self.platform_icons = {
            "hackernews": "ğŸŸ ",
            "producthunt": "ğŸš€",
            "github": "ğŸ™",
            "weibo": "ğŸ”´",
            "wechat": "ğŸ’¬",
            "zhihu": "ğŸ”µ",
            "xiaohongshu": "ğŸ“•",
            "blog": "ğŸ“",
        }

    def _load_database(self) -> Dict:
        """åŠ è½½æ•°æ®åº“"""
        if self.db_path.exists():
            with open(self.db_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            "contents": [],
            "sources": [],
            "last_updated": None
        }

    def _save_database(self):
        """ä¿å­˜æ•°æ®åº“"""
        self.db["last_updated"] = datetime.now().isoformat()
        with open(self.db_path, 'w', encoding='utf-8') as f:
            json.dump(self.db, f, ensure_ascii=False, indent=2)

    def _generate_content_id(self, url: str, title: str) -> str:
        """ç”Ÿæˆå†…å®¹å”¯ä¸€ID"""
        content = f"{url}|{title}"
        return hashlib.md5(content.encode()).hexdigest()[:12]

    def is_duplicate(self, url: str, title: str) -> bool:
        """æ£€æŸ¥å†…å®¹æ˜¯å¦å·²å­˜åœ¨"""
        content_id = self._generate_content_id(url, title)
        return any(c["id"] == content_id for c in self.db["contents"])

    def add_content(self, title: str, url: str, content: str,
                    platform: str, author: str = "", silent: bool = False) -> Optional[Dict]:
        """æ·»åŠ å†…å®¹åˆ°æ•°æ®åº“

        Args:
            title: å†…å®¹æ ‡é¢˜
            url: å†…å®¹URL
            content: å†…å®¹æ­£æ–‡/æ‘˜è¦
            platform: å¹³å°æ¥æº
            author: ä½œè€…/å‘å¸ƒè€…
            silent: é™é»˜æ¨¡å¼ï¼ˆä¸æ‰“å°è¾“å‡ºï¼‰

        Returns:
            æ·»åŠ çš„å†…å®¹æ¡ç›®ï¼Œå¦‚æœé‡å¤åˆ™è¿”å› None
        """
        # æ£€æŸ¥æ˜¯å¦é‡å¤
        if self.is_duplicate(url, title):
            if not silent:
                icon = self.platform_icons.get(platform, "ğŸ“„")
                print(f"âš ï¸  {icon} å†…å®¹å·²å­˜åœ¨ï¼Œè·³è¿‡: {title[:50]}...")
            return None

        content_entry = {
            "id": self._generate_content_id(url, title),
            "title": title,
            "url": url,
            "content": content,
            "platform": platform,
            "author": author,
            "fetched_at": datetime.now().isoformat()
        }

        self.db["contents"].append(content_entry)
        self._save_database()

        if not silent:
            icon = self.platform_icons.get(platform, "ğŸ“„")
            print(f"âœ… {icon} å·²æ·»åŠ : {title[:50]}... ({platform})")

        return content_entry

    def add_source(self, name: str, url: str, platform: str, source_type: str = "web"):
        """æ·»åŠ å†…å®¹æºé…ç½®"""
        source_entry = {
            "name": name,
            "url": url,
            "platform": platform,
            "type": source_type,
            "added_at": datetime.now().isoformat()
        }

        if not any(s["url"] == url and s["platform"] == platform for s in self.db["sources"]):
            self.db["sources"].append(source_entry)
            self._save_database()
            print(f"âœ… å·²æ·»åŠ å†…å®¹æº: {name} ({platform})")

    def get_sources(self, platform: str = None) -> List[Dict]:
        """è·å–å†…å®¹æºåˆ—è¡¨"""
        if platform:
            return [s for s in self.db["sources"] if s["platform"] == platform]
        return self.db["sources"]

    def get_contents(self, platform: str = None, limit: int = None) -> List[Dict]:
        """è·å–å†…å®¹åˆ—è¡¨"""
        contents = self.db["contents"]
        if platform:
            contents = [c for c in contents if c["platform"] == platform]

        contents = sorted(contents, key=lambda x: x["fetched_at"], reverse=True)

        if limit:
            contents = contents[:limit]

        return contents

    def get_stats(self) -> Dict:
        """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            "total_contents": len(self.db["contents"]),
            "total_sources": len(self.db["sources"]),
            "platforms": {},
            "last_updated": self.db["last_updated"]
        }

        for content in self.db["contents"]:
            platform = content["platform"]
            stats["platforms"][platform] = stats["platforms"].get(platform, 0) + 1

        return stats

    def batch_add_contents(self, items: List[Dict]) -> Dict:
        """æ‰¹é‡æ·»åŠ å†…å®¹ï¼ˆå¸¦å¯è§†åŒ–è¿›åº¦ï¼‰

        Args:
            items: å†…å®¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« title, url, content, platform, author

        Returns:
            å¤„ç†ç»“æœç»Ÿè®¡
        """
        if not items:
            return {"total": 0, "added": 0, "skipped": 0, "platforms": {}}

        if self.enable_visual:
            return self._batch_add_with_visual(items)
        else:
            return self._batch_add_basic(items)

    def _batch_add_with_visual(self, items: List[Dict]) -> Dict:
        """ä½¿ç”¨å¯è§†åŒ–è¿›åº¦æ‰¹é‡æ·»åŠ """
        progress = VisualProgress(
            title="ğŸŒ å¤šå¹³å°å†…å®¹è·å–",
            theme="colorful"
        )

        # æŒ‰å¹³å°åˆ†ç»„ç»Ÿè®¡
        platform_stats = {}
        for item in items:
            platform = item.get("platform", "unknown")
            platform_stats[platform] = platform_stats.get(platform, 0) + 1

        # å®šä¹‰å·¥ä½œæµ
        workflow = []
        for platform, count in platform_stats.items():
            icon = self.platform_icons.get(platform, "ğŸ“„")
            workflow.append({
                'id': f'fetch_{platform}',
                'name': f'{icon} è·å– {platform} å†…å®¹ ({count} æ¡)...',
                'total': count
            })

        # ä»»åŠ¡æ‰§è¡Œå‡½æ•°
        def fetch_platform(task_id, info):
            platform = task_id.replace('fetch_', '')
            platform_items = [i for i in items if i.get('platform') == platform]

            added = 0
            skipped = 0

            for idx, item in enumerate(platform_items):
                # æ›´æ–°è¿›åº¦
                current = idx + 1
                yield {'current': current, 'total': len(platform_items)}

                # æ·»åŠ å†…å®¹
                result = self.add_content(
                    title=item.get('title', ''),
                    url=item.get('url', ''),
                    content=item.get('content', ''),
                    platform=item.get('platform', ''),
                    author=item.get('author', ''),
                    silent=True
                )

                if result:
                    added += 1
                else:
                    skipped += 1

            return {'added': added, 'skipped': skipped, 'total': len(platform_items)}

        # æ‰§è¡Œå·¥ä½œæµ
        results = progress.run_tasks(workflow, fetch_platform)

        # æ±‡æ€»ç»Ÿè®¡ - å¤„ç†ä¸åŒçš„è¿”å›æ ¼å¼
        total_added = 0
        total_skipped = 0
        platform_details = {}

        for task_id, result in results.items():
            if isinstance(result, dict):
                added = result.get('added', 0)
                skipped = result.get('skipped', 0)
                total_added += added
                total_skipped += skipped
                platform_details[task_id] = result
            elif isinstance(result, int):
                # å¦‚æœè¿”å›çš„æ˜¯æ•´æ•°ï¼Œè§†ä¸ºæ–°å¢æ•°é‡
                total_added += result
                platform_details[task_id] = {'added': result, 'skipped': 0}

        total_items = len(items)

        return {
            "total": total_items,
            "added": total_added,
            "skipped": total_skipped,
            "platforms": platform_details
        }

    def _batch_add_basic(self, items: List[Dict]) -> Dict:
        """åŸºç¡€æ¨¡å¼æ‰¹é‡æ·»åŠ ï¼ˆæ— å¯è§†åŒ–ï¼‰"""
        print(f"\nğŸ“¥ å¼€å§‹æ‰¹é‡æ·»åŠ  {len(items)} æ¡å†…å®¹...")
        print("=" * 50)

        platform_stats = {}
        added = 0
        skipped = 0

        for idx, item in enumerate(items):
            platform = item.get('platform', 'unknown')
            if platform not in platform_stats:
                platform_stats[platform] = {'added': 0, 'skipped': 0}

            print(f"\n[{idx + 1}/{len(items)}] å¤„ç†: {item.get('title', 'N/A')[:50]}...")

            result = self.add_content(
                title=item.get('title', ''),
                url=item.get('url', ''),
                content=item.get('content', ''),
                platform=platform,
                author=item.get('author', ''),
                silent=False
            )

            if result:
                added += 1
                platform_stats[platform]['added'] += 1
            else:
                skipped += 1
                platform_stats[platform]['skipped'] += 1

        print("\n" + "=" * 50)
        print(f"âœ… å¤„ç†å®Œæˆ: {added} æ¡æ–°å¢, {skipped} æ¡è·³è¿‡")

        return {
            "total": len(items),
            "added": added,
            "skipped": skipped,
            "platforms": platform_stats
        }

    def display_stats_dashboard(self):
        """æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ä»ªè¡¨æ¿"""
        stats = self.get_stats()

        if not self.enable_visual:
            print("\nğŸ“Š æ•°æ®åº“ç»Ÿè®¡")
            print("=" * 50)
            print(f"æ€»å†…å®¹æ•°: {stats['total_contents']}")
            print(f"å†…å®¹æºæ•°: {stats['total_sources']}")
            print(f"æœ€åæ›´æ–°: {stats.get('last_updated', 'N/A')}")

            if stats['platforms']:
                print("\nå„å¹³å°å†…å®¹åˆ†å¸ƒ:")
                for platform, count in sorted(stats['platforms'].items(), key=lambda x: x[1], reverse=True):
                    icon = self.platform_icons.get(platform, "ğŸ“„")
                    print(f"  {icon} {platform}: {count} æ¡")
            return

        # å¯è§†åŒ–ä»ªè¡¨æ¿
        print("\n" + "=" * 60)
        print("ğŸ“Š å¤šå¹³å°å†…å®¹åº“ - æ•°æ®ç»Ÿè®¡")
        print("=" * 60)

        print(f"\nğŸ“ˆ æ€»è§ˆ:")
        print(f"  â€¢ æ€»å†…å®¹æ•°: {stats['total_contents']} æ¡")
        print(f"  â€¢ å†…å®¹æºæ•°: {stats['total_sources']} ä¸ª")
        print(f"  â€¢ æœ€åæ›´æ–°: {stats.get('last_updated', 'N/A')}")

        if stats['platforms']:
            print(f"\nğŸ·ï¸  å¹³å°åˆ†å¸ƒ:")

            # ç»˜åˆ¶ç®€å•æ¡å½¢å›¾
            max_count = max(stats['platforms'].values())
            for platform, count in sorted(stats['platforms'].items(), key=lambda x: x[1], reverse=True):
                icon = self.platform_icons.get(platform, "ğŸ“„")
                bar_length = int(count / max_count * 30)
                bar = "â–ˆ" * bar_length
                print(f"  {icon} {platform:15} {count:4d} æ¡ {bar}")

        print("\n" + "=" * 60)


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description="å¤šå¹³å°å†…å®¹è·å–å™¨ - å¯è§†åŒ–ç‰ˆ")
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # æ·»åŠ å†…å®¹å‘½ä»¤
    add_parser = subparsers.add_parser("add", help="æ·»åŠ å†…å®¹")
    add_parser.add_argument("--title", required=True, help="å†…å®¹æ ‡é¢˜")
    add_parser.add_argument("--url", required=True, help="å†…å®¹URL")
    add_parser.add_argument("--content", required=True, help="å†…å®¹æ­£æ–‡")
    add_parser.add_argument("--platform", required=True, help="å¹³å°åç§°")
    add_parser.add_argument("--author", default="", help="ä½œè€…")

    # æ·»åŠ æºå‘½ä»¤
    source_parser = subparsers.add_parser("add-source", help="æ·»åŠ å†…å®¹æº")
    source_parser.add_argument("--name", required=True, help="æ¥æºåç§°")
    source_parser.add_argument("--url", required=True, help="æ¥æºURL")
    source_parser.add_argument("--platform", required=True, help="å¹³å°åç§°")
    source_parser.add_argument("--type", default="web", help="æ¥æºç±»å‹")

    # åˆ—å‡ºå†…å®¹å‘½ä»¤
    list_parser = subparsers.add_parser("list", help="åˆ—å‡ºå†…å®¹")
    list_parser.add_argument("--platform", help="ç­›é€‰å¹³å°")
    list_parser.add_argument("--limit", type=int, help="é™åˆ¶æ•°é‡")

    # ç»Ÿè®¡å‘½ä»¤
    stats_parser = subparsers.add_parser("stats", help="ç»Ÿè®¡ä¿¡æ¯")
    stats_parser.add_argument("--dashboard", action="store_true", help="æ˜¾ç¤ºä»ªè¡¨æ¿")

    # æ‰¹é‡æ·»åŠ å‘½ä»¤ï¼ˆæ–°å¢ï¼‰
    batch_parser = subparsers.add_parser("batch", help="æ‰¹é‡æ·»åŠ å†…å®¹ï¼ˆå¸¦è¿›åº¦ï¼‰")
    batch_parser.add_argument("--file", required=True, help="åŒ…å«å†…å®¹åˆ—è¡¨çš„ JSON æ–‡ä»¶")

    args = parser.parse_args()

    # åˆ›å»ºè·å–å™¨å®ä¾‹
    fetcher = ContentFetcherVisual(enable_visual=True)

    if args.command == "add":
        fetcher.add_content(
            title=args.title,
            url=args.url,
            content=args.content,
            platform=args.platform,
            author=args.author
        )

    elif args.command == "add-source":
        fetcher.add_source(
            name=args.name,
            url=args.url,
            platform=args.platform,
            source_type=args.type
        )

    elif args.command == "list":
        contents = fetcher.get_contents(platform=args.platform, limit=args.limit)
        print(json.dumps(contents, ensure_ascii=False, indent=2))

    elif args.command == "stats":
        if args.dashboard:
            fetcher.display_stats_dashboard()
        else:
            stats = fetcher.get_stats()
            print(json.dumps(stats, ensure_ascii=False, indent=2))

    elif args.command == "batch":
        # ä»æ–‡ä»¶è¯»å–å†…å®¹åˆ—è¡¨
        with open(args.file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼šç›´æ¥æ•°ç»„æˆ–å¸¦ items å­—æ®µçš„å¯¹è±¡
            items = data if isinstance(data, list) else data.get('items', [])

        if not items:
            print("âŒ æœªæ‰¾åˆ°å¯æ·»åŠ çš„å†…å®¹")
            return

        # æ‰¹é‡æ·»åŠ 
        result = fetcher.batch_add_contents(items)

        # æ˜¾ç¤ºç»“æœ
        print("\nâœ… æ‰¹é‡æ·»åŠ å®Œæˆ:")
        print(f"  æ€»è®¡: {result['total']} æ¡")
        print(f"  æ–°å¢: {result['added']} æ¡")
        print(f"  è·³è¿‡: {result['skipped']} æ¡")

        # ç»Ÿè®¡å„å¹³å°æ•°æ®
        platform_counts = {}
        for item in items:
            platform = item.get('platform', 'unknown')
            platform_counts[platform] = platform_counts.get(platform, 0) + 1

        if platform_counts:
            print("\nå„å¹³å°è¯¦æƒ…:")
            for platform, total in platform_counts.items():
                icon = fetcher.platform_icons.get(platform, "ğŸ“„")
                print(f"  {icon} {platform}: {total} æ¡")

    else:
        parser.print_help()


if __name__ == "__main__":
    main()
