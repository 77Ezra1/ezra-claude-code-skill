#!/usr/bin/env python3
"""
ä¿å­˜å…¬ä¼—å·æ–‡ç« ï¼ˆåŸæ–‡+æ€»ç»“ï¼‰åˆ°Dç›˜
"""

import os
import sys
from datetime import datetime
from pathlib import Path
from urllib.parse import urlparse

sys.path.insert(0, os.path.dirname(__file__))
from fetch_article import fetch_article, WeChatArticleFetcher

# æ–‡ç« ä¿å­˜ç›®å½•
ARTICLES_DIR = "D:/WeChatArticles"


def sanitize_filename(name):
    """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
    illegal_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*']
    for char in illegal_chars:
        name = name.replace(char, '_')
    return name.strip()


def generate_summary(article_data):
    """ç”Ÿæˆæ–‡ç« æ€»ç»“åˆ†æ"""
    title = article_data.get('title', '')
    author = article_data.get('author', '')
    content = article_data.get('content', '')

    return f"""# æ–‡ç« åˆ†æ

## ğŸ“„ åŸºæœ¬ä¿¡æ¯

- **æ ‡é¢˜**: {title}
- **æ¥æº**: {author}
- **é“¾æ¥**: {article_data.get('url', '')}
- **åˆ†ææ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}

---

## ğŸ“ æ ¸å¿ƒæ‘˜è¦

> æ­¤éƒ¨åˆ†éœ€è¦AIæ ¹æ®æ–‡ç« å†…å®¹ç”Ÿæˆ200-300å­—çš„æ ¸å¿ƒæ‘˜è¦

---

## ğŸ¯ å…³é”®è§‚ç‚¹

1. **è§‚ç‚¹ä¸€**
   - å†…å®¹: [å¾…AIåˆ†æ]

2. **è§‚ç‚¹äºŒ**
   - å†…å®¹: [å¾…AIåˆ†æ]

3. **è§‚ç‚¹ä¸‰**
   - å†…å®¹: [å¾…AIåˆ†æ]

---

## ğŸ§  é€»è¾‘ç»“æ„

[å¾…AIæ¢³ç†æ–‡ç« çš„è®ºè¯æ¡†æ¶]

---

## ğŸ’¡ å»¶ä¼¸æ€è€ƒ

- **å€¼å¾—æ¢è®¨çš„é—®é¢˜**: [å¾…AIè¡¥å……]
- **ç›¸å…³è¯é¢˜**: [å¾…AIè¡¥å……]
- **è¡¥å……è§†è§’**: [å¾…AIè¡¥å……]

---

## ğŸ“Š æ–‡ç« é“¾æ¥

- åŸæ–‡é“¾æ¥: {article_data.get('url', '')}
- åŸæ–‡Markdown: ./01_åŸæ–‡.md
"""


def save_article(url, cookie_file=None):
    """ä¿å­˜æ–‡ç« ï¼ˆåŸæ–‡+æ€»ç»“ï¼‰"""
    print(f"Fetching article: {url}")

    # è·å–æ–‡ç« å†…å®¹
    fetcher = WeChatArticleFetcher(cookie_file)
    result = fetcher.fetch_article(url)

    if 'error' in result:
        print(f"[ERROR] Failed to fetch: {result['error']}")
        if 'cookie_help' in result:
            print(f"[TIP] {result['cookie_help']}")
        return False

    # æ¸…ç†æ–‡ä»¶å
    title = sanitize_filename(result['title'])
    author = sanitize_filename(result['author'])
    date_str = datetime.now().strftime('%Y%m%d')

    # åˆ›å»ºæ–‡ç« æ–‡ä»¶å¤¹
    folder_name = f"{date_str}_{author}_{title[:50]}"  # é™åˆ¶é•¿åº¦
    article_dir = Path(ARTICLES_DIR) / folder_name
    article_dir.mkdir(parents=True, exist_ok=True)

    print(f"Folder created: {article_dir}")

    # ä¿å­˜åŸæ–‡
    original_file = article_dir / "01_åŸæ–‡.md"
    with open(original_file, 'w', encoding='utf-8') as f:
        f.write(fetcher.to_markdown(result))
    print(f"[OK] Original saved: {original_file}")

    # ä¿å­˜æ€»ç»“æ¨¡æ¿
    summary_file = article_dir / "02_æ€»ç»“åˆ†æ.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write(generate_summary(result))
    print(f"[OK] Summary saved: {summary_file}")

    print(f"\n[DONE] Article saved successfully!")
    print(f"[DIR] {article_dir}")

    return True


def main():
    import argparse

    parser = argparse.ArgumentParser(description='ä¿å­˜å…¬ä¼—å·æ–‡ç« ï¼ˆåŸæ–‡+æ€»ç»“ï¼‰')
    parser.add_argument('url', help='å…¬ä¼—å·æ–‡ç« é“¾æ¥')
    parser.add_argument('--cookie', help='Cookieé…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    save_article(args.url, args.cookie)


if __name__ == '__main__':
    main()
