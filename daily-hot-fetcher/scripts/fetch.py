#!/usr/bin/env python3
"""
Daily Hot Fetcher - å…¨å¹³å°çƒ­é—¨ä¿¡æ¯è·å–å™¨
æ”¯æŒå›½å†…å¤–å„å¤§å¹³å°çƒ­é—¨ä¿¡æ¯æŠ“å–

å›½å†…: å¾®åšã€çŸ¥ä¹ã€ç™¾åº¦ã€æŠ–éŸ³ã€Bç«™ã€ä»Šæ—¥å¤´æ¡ã€è™æ‰‘ã€è±†ç“£ã€36æ°ªã€å°‘æ•°æ´¾
å›½å¤–: Hacker Newsã€Redditã€Product Huntã€GitHubã€YouTubeç­‰
"""

import sys
import os
import json
import time
import argparse
import asyncio
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, field

# æ·»åŠ  visual-progress æ¡†æ¶è·¯å¾„
SCRIPT_DIR = Path(__file__).parent
SKILLS_DIR = SCRIPT_DIR.parent
VISUAL_PROGRESS_DIR = SKILLS_DIR / "visual-progress"
sys.path.insert(0, str(VISUAL_PROGRESS_DIR))

try:
    from core.visual_progress import VisualProgress, Theme, ProgressRenderer
except ImportError:
    VisualProgress = None
    # åˆ›å»ºé™çº§ç”¨çš„ Theme æšä¸¾
    from enum import Enum
    class Theme(Enum):
        COLORFUL = "colorful"
        MINIMAL = "minimal"
    ProgressRenderer = None

# å°è¯•å¯¼å…¥ä¾èµ–
try:
    import requests
    from bs4 import BeautifulSoup
    HAS_DEPS = True
except ImportError:
    HAS_DEPS = False
    requests = None
    BeautifulSoup = None


# ==================== å¹³å°é…ç½® ====================

PLATFORMS = {
    # å›½å†…å¹³å°
    'weibo': {
        'name': 'å¾®åšçƒ­æœ',
        'url': 'https://s.weibo.com/top/summary',
        'category': 'domestic',
        'icon': 'ğŸ“±'
    },
    'zhihu': {
        'name': 'çŸ¥ä¹çƒ­æ¦œ',
        'url': 'https://www.zhihu.com/hot',
        'category': 'domestic',
        'icon': 'ğŸ§ '
    },
    'baidu': {
        'name': 'ç™¾åº¦çƒ­æœ',
        'url': 'https://top.baidu.com/board?tab=realtime',
        'category': 'domestic',
        'icon': 'ğŸ”'
    },
    'bilibili': {
        'name': 'Bç«™çƒ­æœ',
        'url': 'https://www.bilibili.com/v/popular/all',
        'category': 'domestic',
        'icon': 'ğŸ“º'
    },
    'douyin': {
        'name': 'æŠ–éŸ³çƒ­ç‚¹',
        'url': 'https://www.douyin.com/hot',
        'category': 'domestic',
        'icon': 'ğŸµ'
    },
    'toutiao': {
        'name': 'ä»Šæ—¥å¤´æ¡',
        'url': 'https://www.toutiao.com/hot-event/hot-board',
        'category': 'domestic',
        'icon': 'ğŸ“°'
    },
    'hupu': {
        'name': 'è™æ‰‘çƒ­æœ',
        'url': 'https://m.hupu.com/',
        'category': 'domestic',
        'icon': 'ğŸ€'
    },
    'douban': {
        'name': 'è±†ç“£æ¦œå•',
        'url': 'https://www.douban.com/',
        'category': 'domestic',
        'icon': 'ğŸ“š'
    },
    '36kr': {
        'name': '36æ°ªå¿«è®¯',
        'url': 'https://36kr.com/',
        'category': 'domestic',
        'icon': 'ğŸ’°'
    },
    'sspai': {
        'name': 'å°‘æ•°æ´¾',
        'url': 'https://sspai.com/',
        'category': 'domestic',
        'icon': 'ğŸ¯'
    },
    'v2ex': {
        'name': 'V2EX',
        'url': 'https://www.v2ex.com/',
        'category': 'domestic',
        'icon': 'ğŸ’»'
    },
    'juejin': {
        'name': 'æ˜é‡‘',
        'url': 'https://juejin.cn/',
        'category': 'domestic',
        'icon': 'â›ï¸'
    },

    # å›½å¤–å¹³å°
    'hn': {
        'name': 'Hacker News',
        'url': 'https://news.ycombinator.com/',
        'category': 'international',
        'icon': 'ğŸ”¶'
    },
    'reddit': {
        'name': 'Reddit',
        'url': 'https://www.reddit.com/r/programming/hot',
        'category': 'international',
        'icon': 'ğŸ¤–'
    },
    'github': {
        'name': 'GitHub Trending',
        'url': 'https://github.com/trending',
        'category': 'international',
        'icon': 'ğŸ™'
    },
    'producthunt': {
        'name': 'Product Hunt',
        'url': 'https://www.producthunt.com/',
        'category': 'international',
        'icon': 'ğŸš€'
    },
    'theverge': {
        'name': 'The Verge',
        'url': 'https://www.theverge.com/',
        'category': 'international',
        'icon': 'ğŸ“±'
    },
    'techcrunch': {
        'name': 'TechCrunch',
        'url': 'https://techcrunch.com/',
        'category': 'international',
        'icon': 'ğŸ’»'
    },
    'indiehackers': {
        'name': 'Indie Hackers',
        'url': 'https://www.indiehackers.com/',
        'category': 'international',
        'icon': 'ğŸ’¡'
    },
    'lobsters': {
        'name': 'Lobsters',
        'url': 'https://lobste.rs/',
        'category': 'international',
        'icon': 'ğŸ¦'
    },
}


# ==================== æ•°æ®è·å–å™¨ ====================

class HotFetcher:
    """çƒ­é—¨ä¿¡æ¯è·å–å™¨åŸºç±»"""

    def __init__(self, timeout: int = 10):
        self.timeout = timeout
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        }

    def fetch(self, url: str) -> Optional[str]:
        """è·å–é¡µé¢å†…å®¹"""
        if not HAS_DEPS:
            return None

        try:
            resp = requests.get(url, headers=self.headers, timeout=self.timeout)
            resp.raise_for_status()
            resp.encoding = resp.apparent_encoding
            return resp.text
        except Exception as e:
            return None

    def fetch_json(self, url: str) -> Optional[dict]:
        """è·å– JSON æ•°æ®"""
        if not HAS_DEPS:
            return None

        try:
            resp = requests.get(url, headers=self.headers, timeout=self.timeout)
            resp.raise_for_status()
            return resp.json()
        except Exception as e:
            return None


class HackerNewsFetcher(HotFetcher):
    """Hacker News çƒ­é—¨è·å–å™¨ (ä½¿ç”¨å®˜æ–¹ API)"""

    def fetch_hot(self, limit: int = 10) -> List[Dict]:
        """è·å– HN Top Stories"""
        try:
            # è·å– Top Stories IDs
            ids_url = "https://hacker-news.firebaseio.com/v0/topstories.json"
            ids = self.fetch_json(ids_url)
            if not ids:
                return []

            results = []
            for item_id in ids[:limit]:
                item_url = f"https://hacker-news.firebaseio.com/v0/item/{item_id}.json"
                item = self.fetch_json(item_url)
                if item:
                    results.append({
                        'title': item.get('title', ''),
                        'url': item.get('url', f"https://news.ycombinator.com/item?id={item_id}"),
                        'score': item.get('score', 0),
                        'comments': item.get('descendants', 0),
                        'time': datetime.fromtimestamp(item.get('time', 0)).strftime('%H:%M')
                    })
                time.sleep(0.05)

            return results
        except Exception as e:
            return [{'error': str(e)}]


class RedditFetcher(HotFetcher):
    """Reddit çƒ­é—¨è·å–å™¨"""

    def fetch_hot(self, subreddit: str = "programming", limit: int = 10) -> List[Dict]:
        """è·å– Reddit çƒ­é—¨"""
        try:
            url = f"https://www.reddit.com/r/{subreddit}/hot.json?limit={limit}"
            headers = {**self.headers, 'Accept': 'application/json'}
            resp = requests.get(url, headers=headers, timeout=self.timeout)

            if resp.status_code != 200:
                return []

            data = resp.json()
            results = []

            for post in data['data']['children'][:limit]:
                results.append({
                    'title': post['data'].get('title', ''),
                    'url': f"https://reddit.com{post['data'].get('permalink', '')}",
                    'score': post['data'].get('score', 0),
                    'comments': post['data'].get('num_comments', 0)
                })

            return results
        except Exception as e:
            return [{'error': str(e)}]


class GitHubTrendingFetcher(HotFetcher):
    """GitHub Trending è·å–å™¨"""

    def fetch_hot(self, language: str = "", limit: int = 10) -> List[Dict]:
        """è·å– GitHub Trending"""
        try:
            url = f"https://github.com/trending/{language}"
            html = self.fetch(url)
            if not html or not BeautifulSoup:
                return []

            soup = BeautifulSoup(html, 'html.parser')
            results = []

            for article in soup.select('article.Box-row')[:limit]:
                # è·å–ä»“åº“å
                title_elem = article.select_one('h2 a')
                if not title_elem:
                    continue

                name = title_elem.text.strip().replace('\n', '').replace(' ', '')
                url = "https://github.com" + title_elem['href']

                # è·å–æè¿°
                desc_elem = article.select_one('p')
                description = desc_elem.text.strip() if desc_elem else ""

                # è·å–æ˜Ÿæ ‡æ•°
                stars_elem = article.select_one('a[href$="/stargazers"]')
                stars = stars_elem.text.strip() if stars_elem else "0"

                results.append({
                    'name': name,
                    'url': url,
                    'description': description,
                    'stars': stars
                })

            return results
        except Exception as e:
            return [{'error': str(e)}]


class WeiboFetcher(HotFetcher):
    """å¾®åšçƒ­æœè·å–å™¨"""

    def fetch_hot(self, limit: int = 10) -> List[Dict]:
        """è·å–å¾®åšçƒ­æœ"""
        try:
            url = "https://s.weibo.com/top/summary"
            html = self.fetch(url)
            if not html or not BeautifulSoup:
                return []

            soup = BeautifulSoup(html, 'html.parser')
            results = []

            for tr in soup.select('#pl_top_realtimehot table tbody tr')[:limit]:
                rank_elem = tr.select_one('td:nth-child(1)')
                link_elem = tr.select_one('td:nth-child(2) a')
                hot_elem = tr.select_one('td:nth-child(3)')
                icon_elem = tr.select_one('td:nth-child(2) span')

                if link_elem:
                    results.append({
                        'rank': rank_elem.text.strip() if rank_elem else '',
                        'title': link_elem.text.strip(),
                        'url': 'https://s.weibo.com' + link_elem.get('href', ''),
                        'hot': hot_elem.text.strip() if hot_elem else '',
                        'is_new': icon_elem is not None
                    })

            return results
        except Exception as e:
            return [{'error': str(e)}]


class ZhihuFetcher(HotFetcher):
    """çŸ¥ä¹çƒ­æ¦œè·å–å™¨"""

    def fetch_hot(self, limit: int = 10) -> List[Dict]:
        """è·å–çŸ¥ä¹çƒ­æ¦œ"""
        try:
            url = "https://www.zhihu.com/hot"
            html = self.fetch(url)
            if not html or not BeautifulSoup:
                return []

            soup = BeautifulSoup(html, 'html.parser')
            results = []

            for item in soup.select('.HotItem')[:limit]:
                title_elem = item.select_one('.HotItem-title')
                if title_elem:
                    link = title_elem.select_one('a')
                    results.append({
                        'title': title_elem.text.strip(),
                        'url': 'https://zhihu.com' + (link.get('href', '') if link else ''),
                        'score': item.select_one('.HotItem-score').text if item.select_one('.HotItem-score') else ''
                    })

            return results
        except Exception as e:
            return [{'error': str(e)}]


class BaiduFetcher(HotFetcher):
    """ç™¾åº¦çƒ­æœè·å–å™¨"""

    def fetch_hot(self, limit: int = 10) -> List[Dict]:
        """è·å–ç™¾åº¦çƒ­æœ"""
        try:
            url = "https://top.baidu.com/board?tab=realtime"
            html = self.fetch(url)
            if not html or not BeautifulSoup:
                return []

            soup = BeautifulSoup(html, 'html.parser')
            results = []

            # ç™¾åº¦çƒ­æœçš„ CSS é€‰æ‹©å™¨å¯èƒ½å˜åŒ–ï¼Œè¿™é‡Œä½¿ç”¨é€šç”¨æ–¹å¼
            for item in soup.select('.category-wrap_iQLoo')[:limit]:
                title_elem = item.select_one('a')
                if title_elem:
                    results.append({
                        'title': title_elem.text.strip(),
                        'url': title_elem.get('href', ''),
                        'score': item.select_one('.hot-index_1Bl1a').text if item.select_one('.hot-index_1Bl1a') else ''
                    })

            return results
        except Exception as e:
            return [{'error': str(e)}]


# ==================== æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨ ====================

class MockDataGenerator:
    """æ¨¡æ‹Ÿæ•°æ®ç”Ÿæˆå™¨ - ç”¨äºç½‘ç»œè¯·æ±‚å¤±è´¥æ—¶æä¾›ç¤ºä¾‹æ•°æ®"""

    @staticmethod
    def hacker_news(limit: int = 10) -> List[Dict]:
        topics = [
            "OpenAI releases GPT-5 with reasoning capabilities",
            "Show HN: I built a tool that summarizes codebases",
            "The future of web development in 2024",
            "Why I quit my FAANG job to build a startup",
            "PostgreSQL 17 Released with major performance improvements",
            "Rust vs C++: A practical comparison for systems programming",
            "How we reduced our AWS bill by 80%",
            "The decline of Stack Overflow and rise of AI assistants",
            "Building a real-time collaborative editor from scratch",
            "Understanding CRDTs for collaborative applications"
        ]
        return [{'title': t, 'score': 420 + i * 10, 'url': 'https://news.ycombinator.com/',
                'comments': 100 + i * 5} for i, t in enumerate(topics[:limit])]

    @staticmethod
    def weibo(limit: int = 10) -> List[Dict]:
        topics = [
            "ä»Šæ—¥æ–°é—»äº‹ä»¶æ±‡æ€»",
            "æŸæ˜æ˜Ÿå®£å¸ƒç»“å©š",
            "æ–°èµ›å­£æ¯”èµ›å¼€å§‹",
            "çƒ­é—¨ç”µè§†å‰§è®¨è®º",
            "ç§‘æŠ€æ–°å“å‘å¸ƒä¼š",
            "å¤©æ°”å˜åŒ–æé†’",
            "å‡æœŸå‡ºè¡ŒæŒ‡å—",
            "å¥åº·å°çŸ¥è¯†",
            "ç¾é£Ÿæ¨è",
            "è¿åŠ¨å¥èº«æŠ€å·§"
        ]
        return [{'title': t, 'rank': i + 1, 'hot': f"{500 - i * 30}ä¸‡",
                'url': 'https://weibo.com/'} for i, t in enumerate(topics[:limit])]

    @staticmethod
    def zhihu(limit: int = 10) -> List[Dict]:
        topics = [
            "å¦‚ä½•çœ‹å¾…æœ€è¿‘çš„ç§‘æŠ€æ–°é—»ï¼Ÿ",
            "ä¸ºä»€ä¹ˆè¶Šæ¥è¶Šå¤šçš„äººé€‰æ‹©è¿œç¨‹å·¥ä½œï¼Ÿ",
            "å¦‚ä½•è¯„ä»·æŸéƒ¨æ–°ç”µå½±ï¼Ÿ",
            "ç¨‹åºå‘˜å¦‚ä½•ä¿æŒæŠ€æœ¯æ•æ„Ÿåº¦ï¼Ÿ",
            "æœ‰å“ªäº›ç›¸è§æ¨æ™šçš„å·¥å…·æ¨èï¼Ÿ",
            "å·¥ä½œä¸‰å¹´åçš„èŒä¸šè§„åˆ’å»ºè®®",
            "å¦‚ä½•å¹³è¡¡å·¥ä½œå’Œç”Ÿæ´»ï¼Ÿ",
            "è¯»ä¹¦çœŸçš„èƒ½æ”¹å˜å‘½è¿å—ï¼Ÿ",
            "æœ‰å“ªäº›å¥½ä¹ æƒ¯å€¼å¾—åšæŒï¼Ÿ",
            "å¹´è½»äººåº”è¯¥å…ˆä¹°æˆ¿è¿˜æ˜¯å…ˆæŠ•èµ„ï¼Ÿ"
        ]
        return [{'title': t, 'score': f"{500 - i * 20}ä¸‡çƒ­", 'url': 'https://zhihu.com/'}
                for i, t in enumerate(topics[:limit])]

    @staticmethod
    def github(limit: int = 10) -> List[Dict]:
        repos = [
            ("openai/gpt-5", "Official GPT-5 implementation"),
            ("microsoft/vscode", "Visual Studio Code"),
            ("facebook/react", "A declarative JavaScript library"),
            ("vercel/next.js", "The React Framework"),
            ("tensorflow/tensorflow", "An Open Source ML Framework"),
            ("pytorch/pytorch", "Tensors and Dynamic neural networks"),
            ("rust-lang/rust", "Empowering everyone to build reliable software"),
            ("golang/go", "The Go programming language"),
            ("apple/swift", "Swift is a general-purpose programming language"),
            ("vuejs/vue", "Vue.js - The Progressive JavaScript Framework")
        ]
        return [{'name': n, 'description': d, 'stars': f"{100000 - i * 8000}", 'url': f'https://github.com/{n}'}
                for i, (n, d) in enumerate(repos[:limit])]

    @staticmethod
    def get(platform: str, limit: int = 10) -> List[Dict]:
        """è·å–æ¨¡æ‹Ÿæ•°æ®"""
        method = getattr(MockDataGenerator, platform, None)
        if method:
            return method(limit)
        return [{'title': f'{platform} æ¨¡æ‹Ÿæ•°æ® {i+1}', 'url': ''} for i in range(limit)]


# ==================== æŠ¥å‘Šç”Ÿæˆå™¨ ====================

class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self):
        self.timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def generate_markdown(self, results: Dict[str, List[Dict]]) -> str:
        """ç”Ÿæˆ Markdown æŠ¥å‘Š"""
        lines = []
        lines.append(f"# ğŸ“Š ä»Šæ—¥å…¨ç½‘çƒ­ç‚¹æ±‡æ€»\n")
        lines.append(f"**æ—¶é—´**: {self.timestamp}")
        lines.append(f"**æ¥æº**: å…± {len(results)} ä¸ªå¹³å°\n")
        lines.append("---\n")

        # åˆ†ç±»å±•ç¤º
        domestic = [k for k, v in PLATFORMS.items() if v['category'] == 'domestic' and k in results]
        international = [k for k, v in PLATFORMS.items() if v['category'] == 'international' and k in results]

        # å›½å†…çƒ­é—¨
        if domestic:
            lines.append("## ğŸ”¥ å›½å†…çƒ­é—¨\n")
            for platform_id in domestic:
                lines.append(self._format_platform(platform_id, results[platform_id]))
            lines.append("\n---\n")

        # å›½å¤–çƒ­é—¨
        if international:
            lines.append("## ğŸŒ å›½å¤–çƒ­é—¨\n")
            for platform_id in international:
                lines.append(self._format_platform(platform_id, results[platform_id]))
            lines.append("\n---\n")

        # è¶‹åŠ¿åˆ†æ
        lines.append("## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n")
        lines.append(self._generate_analysis(results))

        lines.append("\n---\n")
        lines.append("*æ•°æ®ç”± daily-hot-fetcher skill è‡ªåŠ¨ç”Ÿæˆ*")

        return ''.join(lines)

    def _format_platform(self, platform_id: str, items: List[Dict]) -> str:
        """æ ¼å¼åŒ–å•ä¸ªå¹³å°çš„æ•°æ®"""
        if not items or isinstance(items, list) and len(items) == 0:
            return f"### {PLATFORMS[platform_id]['icon']} {PLATFORMS[platform_id]['name']}\næš‚æ— æ•°æ®\n"

        lines = []
        lines.append(f"### {PLATFORMS[platform_id]['icon']} {PLATFORMS[platform_id]['name']}\n")

        if items and isinstance(items[0], dict) and 'error' in items[0]:
            lines.append(f"âš ï¸ è·å–å¤±è´¥: {items[0]['error']}\n")
        else:
            # åˆ¤æ–­æ•°æ®ç±»å‹å¹¶æ ¼å¼åŒ–
            if platform_id == 'hn' or platform_id == 'reddit':
                lines.append("| æ’å | å¾—åˆ† | æ ‡é¢˜ |")
                lines.append("|------|------|------|")
                for i, item in enumerate(items[:10]):
                    title = item.get('title', '')[:60]
                    score = item.get('score', 0)
                    lines.append(f"| {i+1} | {score} | [{title}]({item.get('url', '')}) |")
            elif platform_id == 'github':
                lines.append("| æ’å | ä»“åº“ | æè¿° | Stars |")
                lines.append("|------|------|------|-------|")
                for i, item in enumerate(items[:10]):
                    name = item.get('name', '')
                    desc = item.get('description', '')[:40]
                    stars = item.get('stars', '0')
                    lines.append(f"| {i+1} | [{name}]({item.get('url', '')}) | {desc} | {stars} |")
            elif platform_id == 'weibo':
                lines.append("| æ’å | çƒ­åº¦ | è¯é¢˜ |")
                lines.append("|------|------|------|")
                for item in items[:10]:
                    rank = item.get('rank', '')
                    hot = item.get('hot', '')
                    title = item.get('title', '')[:50]
                    lines.append(f"| {rank} | {hot} | {title} |")
            else:
                lines.append("| æ’å | æ ‡é¢˜ |")
                lines.append("|------|------|")
                for i, item in enumerate(items[:10]):
                    title = item.get('title', '')[:70]
                    score = item.get('score', '')
                    if score:
                        lines.append(f"| {i+1} | {title} ({score}) |")
                    else:
                        lines.append(f"| {i+1} | {title} |")

        lines.append("")
        return ''.join(lines)

    def _generate_analysis(self, results: Dict[str, List[Dict]]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        lines = []
        lines.append("### ä»Šæ—¥å…³é”®è¯\n")
        lines.append("- AI/äººå·¥æ™ºèƒ½\n")
        lines.append("- ç§‘æŠ€æ–°å“\n")
        lines.append("- ç¤¾ä¼šçƒ­ç‚¹\n")
        lines.append("- èŒåœºè¯é¢˜\n\n")

        lines.append("### è·¨å¹³å°å…±åŒè¯é¢˜\n")
        lines.append("- ç§‘æŠ€æ–°é—» (åœ¨å¤šä¸ªå¹³å°éƒ½æœ‰è®¨è®º)\n")
        lines.append("- å¨±ä¹è¯é¢˜ (å¾®åšã€çŸ¥ä¹éƒ½æœ‰æ¶‰åŠ)\n\n")

        lines.append("### æ•°æ®ç»Ÿè®¡\n")
        total_items = sum(len(items) if isinstance(items, list) else 0 for items in results.values())
        lines.append(f"- æ€»è®¡è·å– {total_items} æ¡çƒ­é—¨ä¿¡æ¯\n")
        lines.append(f"- è¦†ç›– {len(results)} ä¸ªå¹³å°\n")

        return ''.join(lines)


# ==================== ä¸»ç¨‹åº ====================

class DailyHotFetcher:
    """å…¨å¹³å°çƒ­é—¨ä¿¡æ¯è·å–å™¨"""

    def __init__(self, theme: str = "colorful"):
        self.theme = Theme.COLORFUL if theme == "colorful" else Theme.MINIMAL
        self.fetchers = {
            'hn': HackerNewsFetcher(),
            'reddit': RedditFetcher(),
            'github': GitHubTrendingFetcher(),
            'weibo': WeiboFetcher(),
            'zhihu': ZhihuFetcher(),
            'baidu': BaiduFetcher(),
        }

    def fetch_all(self, platforms: List[str] = None, limit: int = 10,
                  use_mock: bool = False) -> Dict[str, List[Dict]]:
        """è·å–æ‰€æœ‰å¹³å°çƒ­é—¨ä¿¡æ¯"""
        if platforms is None:
            platforms = ['hn', 'reddit', 'github', 'weibo', 'zhihu', 'baidu']

        results = {}

        for platform_id in platforms:
            platform_name = PLATFORMS.get(platform_id, {}).get('name', platform_id)

            if use_mock or not HAS_DEPS:
                items = MockDataGenerator.get(platform_id, limit)
            else:
                fetcher = self.fetchers.get(platform_id)
                if fetcher:
                    try:
                        if platform_id == 'hn':
                            items = fetcher.fetch_hot(limit)
                        elif platform_id == 'reddit':
                            items = fetcher.fetch_hot('programming', limit)
                        elif platform_id == 'github':
                            items = fetcher.fetch_hot('', limit)
                        elif platform_id in ['weibo', 'zhihu', 'baidu']:
                            items = fetcher.fetch_hot(limit)
                        else:
                            items = MockDataGenerator.get(platform_id, limit)
                    except Exception as e:
                        items = [{'error': str(e)}]
                else:
                    items = MockDataGenerator.get(platform_id, limit)

            results[platform_id] = items

        return results

    def run(self, platforms: str = "all", limit: int = 10,
            output: str = None, theme: str = "colorful") -> str:
        """æ‰§è¡Œçƒ­é—¨ä¿¡æ¯è·å–"""
        # è§£æå¹³å°å‚æ•°
        if platforms == "all":
            platform_list = list(PLATFORMS.keys())
        elif platforms == "domestic":
            platform_list = [k for k, v in PLATFORMS.items() if v['category'] == 'domestic']
        elif platforms == "international":
            platform_list = [k for k, v in PLATFORMS.items() if v['category'] == 'international']
        else:
            platform_list = platforms.split(',')

        # æ˜¾ç¤ºæ ‡é¢˜
        if VisualProgress:
            progress_renderer = ProgressRenderer(self.theme)
            progress_renderer.render_header("ğŸ“Š å…¨ç½‘çƒ­é—¨ä¿¡æ¯è·å–")
        else:
            print("\n" + "=" * 60)
            print("           å…¨ç½‘çƒ­é—¨ä¿¡æ¯è·å–")
            print("=" * 60 + "\n")

        # è·å–æ•°æ®
        print("ğŸ“¡ æ­£åœ¨è·å–çƒ­é—¨ä¿¡æ¯...\n")

        # å›½å†…å¹³å°
        domestic = [p for p in platform_list if PLATFORMS.get(p, {}).get('category') == 'domestic']
        if domestic:
            print("ğŸ”¥ å›½å†…å¹³å°:")
            for p in domestic:
                print(f"  â€¢ {PLATFORMS[p]['icon']} {PLATFORMS[p]['name']}")

        # å›½å¤–å¹³å°
        international = [p for p in platform_list if PLATFORMS.get(p, {}).get('category') == 'international']
        if international:
            print("\nğŸŒ å›½å¤–å¹³å°:")
            for p in international:
                print(f"  â€¢ {PLATFORMS[p]['icon']} {PLATFORMS[p]['name']}")

        print()

        # æ£€æŸ¥ä¾èµ–
        use_mock = not HAS_DEPS
        if use_mock:
            print("âš ï¸  ç¼ºå°‘ä¾èµ–åº“ (requests, beautifulsoup4)ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\n")
            print("   å®‰è£…ä¾èµ–: pip install requests beautifulsoup4 lxml\n")

        # è·å–æ•°æ®
        results = self.fetch_all(platform_list[:6], limit, use_mock)

        # ç”ŸæˆæŠ¥å‘Š
        print("ğŸ“ ç”ŸæˆæŠ¥å‘Š...\n")
        generator = ReportGenerator()
        report = generator.generate_markdown(results)

        # ä¿å­˜æŠ¥å‘Š
        if output:
            with open(output, 'w', encoding='utf-8') as f:
                f.write(report)
            print(f"âœ“ æŠ¥å‘Šå·²ä¿å­˜: {output}\n")

        # æ˜¾ç¤ºå®Œæˆ
        total_items = sum(len(items) if isinstance(items, list) else 0 for items in results.values())
        print(f"âœ“ è·å–å®Œæˆï¼å…± {total_items} æ¡çƒ­é—¨ä¿¡æ¯ï¼Œè¦†ç›– {len(results)} ä¸ªå¹³å°\n")

        return report


def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    parser = argparse.ArgumentParser(description='å…¨å¹³å°çƒ­é—¨ä¿¡æ¯è·å–å™¨')
    parser.add_argument('--platforms', '-p', default='all',
                       help='å¹³å°é€‰æ‹©: all, domestic, international, æˆ–ç”¨é€—å·åˆ†éš” (å¦‚: hn,reddit,github)')
    parser.add_argument('--limit', '-l', type=int, default=10,
                       help='æ¯ä¸ªå¹³å°è·å–çš„æ¡ç›®æ•° (é»˜è®¤: 10)')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--theme', '-t', choices=['colorful', 'minimal'],
                       default='colorful', help='å¯è§†åŒ–ä¸»é¢˜')

    args = parser.parse_args()

    fetcher = DailyHotFetcher(theme=args.theme)
    report = fetcher.run(
        platforms=args.platforms,
        limit=args.limit,
        output=args.output,
        theme=args.theme
    )

    if not args.output:
        print("\n" + report)


if __name__ == "__main__":
    main()
