#!/usr/bin/env python3
"""
EPUB to Markdown Converter

çº¯ Python å®ç°ï¼Œä½¿ç”¨ zipfile ç›´æ¥æå– EPUB å†…å®¹ã€‚
EPUB æœ¬è´¨æ˜¯ ZIP æ ¼å¼ï¼ŒåŒ…å« HTML/XHTML æ–‡ä»¶å’Œèµ„æºã€‚
"""
import argparse
import json
import os
import re
import sys
import zipfile
from pathlib import Path
from html.parser import HTMLParser
from html.entities import name2codepoint
from xml.etree import ElementTree as ET


class MarkdownExtractor(HTMLParser):
    """HTML to Markdown è½¬æ¢å™¨"""

    def __init__(self):
        super().__init__()
        self.markdown = []
        self.in_style = False
        self.in_script = False
        self.list_depth = 0
        self.list_type = []  # 'ul' or 'ol'
        self.current_list_item = []

    def handle_starttag(self, tag, attrs):
        self.in_style = tag in ['style', 'script']
        if self.in_style:
            return

        if tag in ['h1', 'h2', 'h3', 'h4', 'h5', 'h6']:
            level = tag[1]
            self.markdown.append(f"\n\n{'#' * int(level)} ")

        elif tag == 'p':
            if self.markdown and not self.markdown[-1].endswith('\n\n'):
                self.markdown.append('\n\n')

        elif tag == 'br':
            self.markdown.append('  \n')

        elif tag in ['b', 'strong']:
            self.markdown.append('**')

        elif tag in ['i', 'em']:
            self.markdown.append('*')

        elif tag == 'a':
            href = dict(attrs).get('href', '')
            self.markdown.append('[')
            self.current_href = href

        elif tag in ['ul', 'ol']:
            self.list_depth += 1
            self.list_type.append('ul' if tag == 'ul' else 'ol')
            self.markdown.append('\n')

        elif tag == 'li':
            indent = '  ' * (self.list_depth - 1)
            if self.list_type and self.list_type[-1] == 'ol':
                self.markdown.append(f'{ind}1. ')
            else:
                self.markdown.append(f'{ind}- ')

        elif tag == 'img':
            src = dict(attrs).get('src', '')
            alt = dict(attrs).get('alt', '')
            self.markdown.append(f'![{alt}]({src})')

        elif tag == 'blockquote':
            self.markdown.append('> ')

        elif tag == 'code':
            self.markdown.append('`')

        elif tag == 'pre':
            self.markdown.append('\n```\n')

        elif tag == 'hr':
            self.markdown.append('\n\n---\n\n')

    def handle_endtag(self, tag):
        self.in_style = False

        if tag in ['b', 'strong']:
            self.markdown.append('**')

        elif tag in ['i', 'em']:
            self.markdown.append('*')

        elif tag == 'a':
            href = getattr(self, 'current_href', '')
            self.markdown.append(f']({href})')

        elif tag in ['ul', 'ol']:
            self.list_depth -= 1
            if self.list_type:
                self.list_type.pop()
            self.markdown.append('\n')

        elif tag == 'code':
            self.markdown.append('`')

        elif tag == 'pre':
            self.markdown.append('\n```\n\n')

    def handle_data(self, data):
        if self.in_style or self.in_script:
            return
        self.markdown.append(data)

    def handle_entityref(self, name):
        if name in name2codepoint:
            self.markdown.append(chr(name2codepoint[name]))

    def handle_charref(self, name):
        try:
            self.markdown.append(chr(int(name[1:] if name.startswith('x') else name)))
        except ValueError:
            pass

    def get_markdown(self):
        return ''.join(self.markdown).strip()


def parse_epub_metadata(epub_path):
    """è§£æ EPUB å…ƒæ•°æ®"""
    with zipfile.ZipFile(epub_path, 'r') as zf:
        # æŸ¥æ‰¾ .opf æ–‡ä»¶
        opf_files = [f for f in zf.namelist() if f.endswith('.opf')]
        if not opf_files:
            return {}

        with zf.open(opf_files[0]) as f:
            tree = ET.parse(f)
            root = tree.getroot()

            # å‘½åç©ºé—´
            ns = {'dc': 'http://purl.org/dc/elements/1.1/',
                  'opf': 'http://www.idpf.org/2007/opf'}

            metadata = {}
            title_elem = root.find('dc:title', ns)
            if title_elem is not None:
                metadata['title'] = title_elem.text

            creator_elem = root.find('dc:creator', ns)
            if creator_elem is not None:
                metadata['author'] = creator_elem.text

            language_elem = root.find('dc:language', ns)
            if language_elem is not None:
                metadata['language'] = language_elem.text

            publisher_elem = root.find('dc:publisher', ns)
            if publisher_elem is not None:
                metadata['publisher'] = publisher_elem.text

            identifier_elem = root.find('dc:identifier', ns)
            if identifier_elem is not None:
                metadata['isbn'] = identifier_elem.text

            return metadata


def get_content_files(epub_path):
    """è·å– EPUB ä¸­çš„å†…å®¹æ–‡ä»¶åˆ—è¡¨ï¼ˆæŒ‰é˜…è¯»é¡ºåºï¼‰"""
    with zipfile.ZipFile(epub_path, 'r') as zf:
        # æŸ¥æ‰¾ .opf æ–‡ä»¶
        opf_files = [f for f in zf.namelist() if f.endswith('.opf')]
        if not opf_files:
            return []

        with zf.open(opf_files[0]) as f:
            tree = ET.parse(f)
            root = tree.getroot()

            # æŸ¥æ‰¾ manifest
            ns = {'opf': 'http://www.idpf.org/2007/opf'}
            manifest = root.find('opf:manifest', ns)

            if manifest is None:
                return []

            # è·å–æ‰€æœ‰ HTML/XHTML æ–‡ä»¶
            items = manifest.findall('opf:item', ns)
            content_files = []

            for item in items:
                media_type = item.get('media-type', '')
                href = item.get('href', '')

                if 'html' in media_type or href.endswith(('.html', '.xhtml')):
                    # è·å–å®Œæ•´è·¯å¾„
                    opf_dir = os.path.dirname(opf_files[0])
                    full_path = os.path.normpath(os.path.join(opf_dir, href))
                    content_files.append(full_path)

            return content_files


def extract_images(epub_path, output_dir):
    """æå– EPUB ä¸­çš„å›¾ç‰‡"""
    output_dir = Path(output_dir)
    images_dir = output_dir / 'images'
    images_dir.mkdir(parents=True, exist_ok=True)

    image_mapping = {}

    with zipfile.ZipFile(epub_path, 'r') as zf:
        for name in zf.namelist():
            if name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.svg')):
                # ä¿ç•™åŸå§‹æ–‡ä»¶å
                filename = os.path.basename(name)
                output_path = images_dir / filename

                with zf.open(name) as source, open(output_path, 'wb') as target:
                    target.write(source.read())

                # è®°å½•åŸå§‹è·¯å¾„åˆ°æœ¬åœ°è·¯å¾„çš„æ˜ å°„
                image_mapping[name] = f'images/{filename}'

    return image_mapping


def convert_epub_to_markdown(epub_path, output_dir, extract_images_flag=False,
                             split_chapters=False):
    """å°† EPUB è½¬æ¢ä¸º Markdown"""
    epub_path = Path(epub_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ“– æ­£åœ¨å¤„ç†: {epub_path.name}")

    # è§£æå…ƒæ•°æ®
    print("   è§£æå…ƒæ•°æ®...")
    metadata = parse_epub_metadata(epub_path)
    metadata['source_file'] = epub_path.name

    # æå–å›¾ç‰‡
    image_mapping = {}
    if extract_images_flag:
        print("   æå–å›¾ç‰‡...")
        image_mapping = extract_images(epub_path, output_dir)
        print(f"   å·²æå– {len(image_mapping)} å¼ å›¾ç‰‡")

    # è·å–å†…å®¹æ–‡ä»¶
    content_files = get_content_files(epub_path)
    print(f"   æ‰¾åˆ° {len(content_files)} ä¸ªå†…å®¹æ–‡ä»¶")

    # è½¬æ¢å†…å®¹
    all_content = []
    chapters = []

    with zipfile.ZipFile(epub_path, 'r') as zf:
        for i, content_file in enumerate(content_files, 1):
            if content_file not in zf.namelist():
                continue

            print(f"   è½¬æ¢æ–‡ä»¶ {i}/{len(content_files)}: {os.path.basename(content_file)}")

            with zf.open(content_file) as f:
                html_content = f.read().decode('utf-8', errors='ignore')

            # è½¬æ¢ä¸º Markdown
            extractor = MarkdownExtractor()
            extractor.feed(html_content)
            markdown_content = extractor.get_markdown()

            # æ›´æ–°å›¾ç‰‡è·¯å¾„
            for orig_path, new_path in image_mapping.items():
                markdown_content = markdown_content.replace(orig_path, new_path)

            if split_chapters:
                # æ£€æµ‹ç« èŠ‚æ ‡é¢˜
                title_match = re.search(r'^#\s+(.+)$', markdown_content, re.MULTILINE)
                if title_match:
                    title = title_match.group(1).strip()
                else:
                    title = f"Chapter_{i:02d}"

                # æ¸…ç†æ–‡ä»¶å
                safe_title = re.sub(r'[<>:"/\\|?*]', '_', title)
                chapter_file = output_dir / 'chapters' / f"chapter_{i:02d}_{safe_title}.md"

                (output_dir / 'chapters').mkdir(exist_ok=True)

                with open(chapter_file, 'w', encoding='utf-8') as f:
                    f.write(markdown_content)

                chapters.append({
                    'id': f'ch{i}',
                    'title': title,
                    'file': f"chapters/{chapter_file.name}"
                })

            all_content.append(markdown_content)

    # ç”Ÿæˆå®Œæ•´ Markdown
    full_markdown = f"# {metadata.get('title', 'æœªçŸ¥æ ‡é¢˜')}\n\n"
    full_markdown += f"**ä½œè€…**: {metadata.get('author', 'æœªçŸ¥')}\n\n"
    full_markdown += "---\n\n"
    full_markdown += '\n\n'.join(all_content)

    if split_chapters:
        full_file = output_dir / 'full_book.md'
        metadata['chapters'] = chapters
    else:
        # ä½¿ç”¨ä¹¦åä½œä¸ºæ–‡ä»¶å
        safe_title = re.sub(r'[<>:"/\\|?*]', '_', metadata.get('title', 'output'))
        full_file = output_dir / f"{safe_title}.md"

    with open(full_file, 'w', encoding='utf-8') as f:
        f.write(full_markdown)

    # ä¿å­˜å…ƒæ•°æ®
    metadata_file = output_dir / 'book_metadata.json'
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    # ç»Ÿè®¡ä¿¡æ¯
    word_count = len(full_markdown.split())

    print(f"\nâœ… è½¬æ¢å®Œæˆ!")
    print(f"ğŸ“„ è¾“å‡ºæ–‡ä»¶: {full_file.name}")
    print(f"ğŸ“Š å­—æ•°: çº¦ {word_count:,} å­—")
    if extract_images_flag:
        print(f"ğŸ–¼ï¸ å›¾ç‰‡: å·²æå– {len(image_mapping)} å¼ ")
    if split_chapters:
        print(f"ğŸ“– ç« èŠ‚: å·²æ‹†åˆ† {len(chapters)} ç« ")
    print(f"ğŸ“ ä¿å­˜ä½ç½®: {output_dir}")

    return {
        'success': True,
        'output_file': str(full_file),
        'metadata_file': str(metadata_file),
        'word_count': word_count,
        'image_count': len(image_mapping),
        'chapter_count': len(chapters) if split_chapters else 0
    }


def batch_convert(input_dir, output_dir, **kwargs):
    """æ‰¹é‡è½¬æ¢ EPUB æ–‡ä»¶"""
    input_dir = Path(input_dir)
    output_dir = Path(output_dir)

    epub_files = list(input_dir.glob('*.epub'))

    if not epub_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ° EPUB æ–‡ä»¶")
        return

    print(f"ğŸ“š æ‰¾åˆ° {len(epub_files)} ä¸ª EPUB æ–‡ä»¶\n")

    results = []
    for i, epub_file in enumerate(epub_files, 1):
        print(f"\n[{i}/{len(epub_files)}] ", end='')
        book_output = output_dir / epub_file.stem

        try:
            result = convert_epub_to_markdown(epub_file, book_output, **kwargs)
            results.append(result)
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {e}")
            results.append({'success': False, 'error': str(e)})

    # æ±‡æ€»
    successful = sum(1 for r in results if r.get('success'))
    print(f"\n\n{'='*50}")
    print(f"âœ… æ‰¹é‡è½¬æ¢å®Œæˆ: {successful}/{len(epub_files)} æˆåŠŸ")


def main():
    parser = argparse.ArgumentParser(
        description='å°† EPUB ç”µå­ä¹¦è½¬æ¢ä¸º Markdown æ ¼å¼',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è½¬æ¢å•ä¸ªæ–‡ä»¶
  python convert_epub.py book.epub -o output

  # æ‰¹é‡è½¬æ¢
  python convert_epub.py --batch ~/Downloads/epubs -o output

  # æå–å›¾ç‰‡
  python convert_epub.py book.epub -o output --extract-images

  # æŒ‰ç« èŠ‚æ‹†åˆ†
  python convert_epub.py book.epub -o output --split-chapters
        """
    )

    parser.add_argument('input', nargs='?', help='EPUB æ–‡ä»¶æˆ–ç›®å½•ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰')
    parser.add_argument('-o', '--output', default='output', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--batch', action='store_true', help='æ‰¹é‡è½¬æ¢æ¨¡å¼')
    parser.add_argument('--extract-images', action='store_true',
                        help='æå–å›¾ç‰‡åˆ° images/ ç›®å½•')
    parser.add_argument('--split-chapters', action='store_true',
                        help='æŒ‰ç« èŠ‚æ‹†åˆ†ä¸ºå¤šä¸ªæ–‡ä»¶')

    args = parser.parse_args()

    if not args.input:
        parser.print_help()
        return

    kwargs = {
        'extract_images_flag': args.extract_images,
        'split_chapters': args.split_chapters
    }

    if args.batch:
        batch_convert(args.input, args.output, **kwargs)
    else:
        convert_epub_to_markdown(args.input, args.output, **kwargs)


if __name__ == '__main__':
    main()
